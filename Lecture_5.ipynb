{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBjEYPaPOHrq"
      },
      "source": [
        "# Lecture 5\n",
        "\n",
        "## Introduction to Keras\n",
        "- Keras is an open source deep learning framework for Python\n",
        "- It provides high-level building blocks for developing deep learning models\n",
        "- It has been developed by an artificial intelligence researcher at Google named Francois Chollet\n",
        "- Currently used by many leading companies\n",
        "\n",
        "### What is Keras?\n",
        "\n",
        "- Keras is a high-level interface for more specialized, well-optimized tensor manipulation libraries.\n",
        "  - Such libraries serve as the **backend engigne** of Keras\n",
        "    - TensorFlow, or Microsoft Cognitive Toolkit (CNTK), or Theano\n",
        "\n",
        "- It does not handle itself low-level operations such as tensor products, convolutions, etc.\n",
        "- It was developed with a focus on enabling fast experimentation\n",
        "\n",
        "\n",
        "## Tensorflow\n",
        "- open-source software library\n",
        "- Intensely optimized for fast Numerical computations\n",
        "- Widely used for Machine Learning/Deep Learning\n",
        "- First public release, TensorFlow 1.0.0, 2017\n",
        "- Based on tensors: Generalization of vectors and matrices to potentially higher dimensions\n",
        "\n",
        "- Everything is a tensor!\n",
        "  - A scalar is a tensor of dimension 0\n",
        "  - A vector is a tensor of dimension 1\n",
        "  - A matrix is a tensor of dimension 2\n",
        "- Say you have N images, each of size H x W - represent that as a tensor of dimension N x H x W\n",
        "- Tensorflow is literally the flow of tensors\n",
        "* Symbolic tensor manipulation framework developed by Google\n",
        "\n",
        "* The idea of a computational graph is central to TensorFlow\n",
        "\n",
        "- In Tensorflow 2.0 not necessary anymore to define placeholder to run computations\n",
        "\n",
        "* Eager computation: allows to direct invoke the operand\n",
        "\n",
        "* less efficient: used just for interactive computation\n",
        "* tf.enable_eager_execution() must be called at program startup, **let's restart the session**, the run the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y2-gWKAOEic",
        "outputId": "0dbcf456-18a4-4241-8f86-4f29e46e784d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.5      , 3.       , 1.9000001], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "operand1 = [1.5, 2, 2.9]\n",
        "operand2 = [0, 1, -1]\n",
        "tf.add(operand1, operand2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "073HvuA41a9C"
      },
      "source": [
        "* Tensorflow low level operation are hidden when programming with Keras\n",
        "* We can import keras directly or import tensorflow.keras\n",
        "* Since the Keras release 2.3.0 Keras and tensorflow.keras are in sync   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZBYLd7E1dPb",
        "outputId": "ac4455b9-5bb0-4f74-8673-e5654281fc41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.4.1\n",
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras as K\n",
        "print(K.__version__)\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cMiVWfk1o1G"
      },
      "source": [
        "- Keras model accept 3 types of inputs:\n",
        "  - Numpy arrays, like scikit-learn\n",
        "  - Tensorflow Dataset objects\n",
        "  - Python generators that yoeld batches of data\n",
        "\n",
        "- We know build an MLP to classify MNIST handwritten digits (keras has its own dataset module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T3ttDw_1oZ9",
        "outputId": "3ae0d902-2d31-4c56-cde9-d93a9a2bca1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "X_train.shape:(60000, 28, 28),    X_train type :<class 'numpy.ndarray'>\n",
            "X_test.shape:(10000, 28, 28),    X_test type :<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(f\"X_train.shape:{X_train.shape},\\\n",
        "    X_train type :{type(X_train)}\")\n",
        "print(f\"X_test.shape:{X_test.shape},\\\n",
        "    X_test type :{type(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQiXHsMK2M3z"
      },
      "source": [
        "- We have 60000 samples in our training set belonging to 10 classes.\n",
        "- The images are 28x28 pixels each. We can confirm this by plotting the first sample in matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "NTwwf0pB2aI6",
        "outputId": "5c530fb7-5a4c-42f8-c332-ab04ed922d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes: [0 1 2 3 4 5 6 7 8 9]\n",
            "[5 0 4 1 9 2 1 3 1 4]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(X_train[0])\n",
        "print(f'Unique classes: {np.unique(y_train)}')\n",
        "print(y_train[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Eutld-32o-5"
      },
      "source": [
        "- MLP takes vectors as inputs\n",
        "- How to change images into MLP input?\n",
        "  We vectorize them by using the reshape() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdFkAtYT2zHR",
        "outputId": "075d8960-497d-43e4-ddc3-7d0899791001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape:(60000, 784)\n",
            "X_test.shape:(10000, 784)\n",
            "X_train.dtype:uint8\n",
            "X_train.dtype:float32\n"
          ]
        }
      ],
      "source": [
        "# reshaping all the training and testing datasets by removing one dimension\n",
        "X_train = X_train.reshape(-1, 28*28)\n",
        "print(f\"X_train.shape:{X_train.shape}\")\n",
        "\n",
        "X_test = X_test.reshape(-1, 28*28)\n",
        "print(f\"X_test.shape:{X_test.shape}\")\n",
        "\n",
        "# keras models need float32 inputs\n",
        "print(f\"X_train.dtype:{X_train.dtype}\")\n",
        "X_train = X_train.astype('float32')\n",
        "print(f\"X_train.dtype:{X_train.dtype}\")\n",
        "X_test = X_test.astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK8Ph8Xf3RId"
      },
      "source": [
        "### Keras Sequential Model\n",
        "- Sequential model is basically a linear composition of Keras Layers.\n",
        "  - It creates a FFNN\n",
        "- This is simply a linear stack of neural network layers, and it's perfect for the type of feed-forward model like MLP\n",
        "\n",
        "We know import the Sequential model type from Keras and the first layer type Dense.\n",
        "  - A fully-connected layer, like in MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hGrji65_3Q5C"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "# dense is a fully connected layer\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLK01Jd592sh"
      },
      "source": [
        "tf.keras.layers.Dense(units=,\n",
        "                      activation=None,\n",
        "                      use_bias=True,\n",
        "                      kernel_initializer='glorot_uniform',\n",
        "                      bias_initializer='zeros',\n",
        "                      kernel_regularizer=None,\n",
        "                      bias_regularizer=None,\n",
        "                      activity_regularizer=None,\n",
        "                      kernel_constraint=None,\n",
        "                      bias_constraint=None,\n",
        "                      **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGeho6Hd4VoY"
      },
      "source": [
        "- units - positive integer, dimensionality of the output space\n",
        "- activation - activation function to use. If we don't specify anything, no activation is applied (linear activation a(x) = x)\n",
        "- use_bias - boolean, whether the layer uses a bias vector.\n",
        "- kernel_initializer - initializer for the kernel weights matrix\n",
        "- bias_initializer - initializer for the bias vector\n",
        "- kernel_regularizer - regularizer function applied to the kernel weights matrix\n",
        "- bias_regularizer - regularizer function applied to the bias vector\n",
        "- activity_regularizer - regularizer function applied to the output of the layer (its 'activation')\n",
        "- kernel_constraint - constraint function applied to the kernel weights matrix\n",
        "- bias_constraint - constraint function applied to the bias vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbnm83Te6lih",
        "outputId": "260ec23c-b14e-491b-88cf-ca36632375d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42) # for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "print(f'Number of classes: {num_classes}')\n",
        "\n",
        "# create a Sequential model\n",
        "model = Sequential([\n",
        "    # First hidden layer. Input data with size 28*28 and output size 256\n",
        "        #   256 means you set up this layer with 256 hidden neurons.\n",
        "        #   Such a value is up to you, typically an hyper-parameter\n",
        "        # input_shape must be specified just for the first hidden layer\n",
        "        # in (28*28,) the comma indicates the dimension of the batches,\n",
        "        #     unknowkn during the implementation\n",
        "    Dense(256, input_shape=(28*28,), activation='sigmoid'),\n",
        "\n",
        "    # Second hidden layer. Input data with size 256,\n",
        "        #    which were same to output of the first hidden layer.\n",
        "        #    output size 128, we set up 128 neurons  in this hidden layer.\n",
        "        # No need to give input size here because keras gets it automatically.\n",
        "    Dense(128, activation='sigmoid'),\n",
        "\n",
        "    # output layer. the number of output should be your number\n",
        "        #    of classification\n",
        "        # Softmx for multiclass classification\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkbUVltb7Lpk"
      },
      "source": [
        "Alternatively, we can define the model and then the add() method to add layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yLd6SBgq7QYK"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42) # for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "## alternative definition usinf Sequential.add()\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(28*28,), activation='sigmoid'))\n",
        "model.add(Dense(128, activation='sigmoid'))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7_kxR8p97Ai"
      },
      "source": [
        "- Third alternative, we can use the tensorflow.keras.Model class, along with an tensorflow.keras.Input class\n",
        "  - This alternativee is useful when we need to define models with multiple inputs and/or multiple outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SviQB1_h-PHO"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "input = tf.keras.Input(shape=(28*28,))\n",
        "hid = tf.keras.layers.Dense(256, activation='sigmoid')(input)\n",
        "hid = tf.keras.layers.Dense(128, activation='sigmoid')(hid)\n",
        "output = tf.keras.layers.Dense(num_classes, activation='sigmoid')(hid)\n",
        "model = tf.keras.Model(input, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "3l917eV8AA3Z",
        "outputId": "7b71bedc-0398-414b-f557-4ae14e4cde57"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m200,960\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,146\u001b[0m (918.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,146</span> (918.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary() # print out the model structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJsZ3GOaAOSw"
      },
      "source": [
        "Number of Parameters:\n",
        "- First layer: **input size** = 784+1(+1 for bias), **output size** = 256. we have totally (784+1)* 256 = 200960 parameters\n",
        "\n",
        "- Second layer: **input size** = 256 + 1, **output size** = 128. We have totally (256+1)* 128 = 32896 parameters\n",
        "\n",
        "- output layer: **input size** = 128 + 1, **output size** = 10. We have totally (128+1)* 10 = 1290 parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWjIhTonAu57"
      },
      "source": [
        "Compile the model:\n",
        "- Keras Model class provides a method, compile() to compile the model\n",
        "- It transforms the model into a computational graph (possibly static), to get the best execution performance.\n",
        "- The argument and default value of the compile() method is as follows:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r-yXqxVjbd5"
      },
      "source": [
        "Model.compile(optimizer='rmsprop',\n",
        "              loss=None,\n",
        "              metrics=None,\n",
        "              loss_weights=None,\n",
        "              weighted_metrics=None,\n",
        "              run_eagerly=None,\n",
        "              steps_per_execution=None,\n",
        "              jit_compile=None,\n",
        "              **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ4kdup7Cprr"
      },
      "source": [
        "Parameters:\n",
        "- **optimizer**: String (name of optimizer) or optimizer instance. See tf.keras.optimizers\n",
        "\n",
        "* **loss**: Loss function. May be a string (name of loss function), or a tf.keras.losses.Loss instance. See tf.keras.losses\n",
        "\n",
        "* **metrics**: List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. See tf.keras.metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rXYTC523JyX2"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='SGD', # stochastic gradient descent\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dufH0W8KA0W"
      },
      "source": [
        "- sparse_categorical_crossentropy:\n",
        "  - It is the cross entropy (CE) loss, the sparse stands for automatic transformation of the labels into one-hot vectors\n",
        "    - we do not need to transform them manually\n",
        "    - we can provide the integer labels 0, ..., 9\n",
        "  - As studied, CE is suitable for multiclass classification\n",
        "  - We expect labels to be provided as integers\n",
        "  - Use CategoricalCrossentropy loss if we want to provide lables using one-hot representation\n",
        "\n",
        "  ### Fitting/Training the model\n",
        "\n",
        "  - We invoke the method fit on the Model instance\n",
        "  - THe whole training is hidden!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B8H_wd5J_Xy",
        "outputId": "3e45366b-9868-461a-bc26-53bd33fd315c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.5251 - loss: 1.8907 - val_accuracy: 0.8640 - val_loss: 0.8932\n",
            "Epoch 2/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.8217 - val_accuracy: 0.9017 - val_loss: 0.5110\n",
            "Epoch 3/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 0.5313 - val_accuracy: 0.9162 - val_loss: 0.3783\n",
            "Epoch 4/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.4185 - val_accuracy: 0.9240 - val_loss: 0.3180\n",
            "Epoch 5/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.3585 - val_accuracy: 0.9343 - val_loss: 0.2778\n",
            "Epoch 6/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.3180 - val_accuracy: 0.9367 - val_loss: 0.2516\n",
            "Epoch 7/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2915 - val_accuracy: 0.9410 - val_loss: 0.2324\n",
            "Epoch 8/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2696 - val_accuracy: 0.9428 - val_loss: 0.2208\n",
            "Epoch 9/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9303 - loss: 0.2514 - val_accuracy: 0.9468 - val_loss: 0.2049\n",
            "Epoch 10/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9330 - loss: 0.2371 - val_accuracy: 0.9480 - val_loss: 0.1969\n",
            "Epoch 11/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.2243 - val_accuracy: 0.9523 - val_loss: 0.1856\n",
            "Epoch 12/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2130 - val_accuracy: 0.9540 - val_loss: 0.1792\n",
            "Epoch 13/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.2018 - val_accuracy: 0.9542 - val_loss: 0.1740\n",
            "Epoch 14/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1964 - val_accuracy: 0.9587 - val_loss: 0.1629\n",
            "Epoch 15/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1841 - val_accuracy: 0.9563 - val_loss: 0.1620\n",
            "Epoch 16/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.1787 - val_accuracy: 0.9597 - val_loss: 0.1547\n",
            "Epoch 17/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9527 - loss: 0.1714 - val_accuracy: 0.9607 - val_loss: 0.1533\n",
            "Epoch 18/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1641 - val_accuracy: 0.9633 - val_loss: 0.1485\n",
            "Epoch 19/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9568 - loss: 0.1582 - val_accuracy: 0.9625 - val_loss: 0.1439\n",
            "Epoch 20/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9576 - loss: 0.1554 - val_accuracy: 0.9623 - val_loss: 0.1402\n",
            "Epoch 21/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9590 - loss: 0.1475 - val_accuracy: 0.9638 - val_loss: 0.1386\n",
            "Epoch 22/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.1435 - val_accuracy: 0.9632 - val_loss: 0.1353\n",
            "Epoch 23/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1389 - val_accuracy: 0.9640 - val_loss: 0.1307\n",
            "Epoch 24/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.1341 - val_accuracy: 0.9660 - val_loss: 0.1277\n",
            "Epoch 25/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1300 - val_accuracy: 0.9670 - val_loss: 0.1255\n",
            "Epoch 26/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.1283 - val_accuracy: 0.9662 - val_loss: 0.1230\n",
            "Epoch 27/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.1234 - val_accuracy: 0.9678 - val_loss: 0.1203\n",
            "Epoch 28/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1195 - val_accuracy: 0.9675 - val_loss: 0.1192\n",
            "Epoch 29/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.1169 - val_accuracy: 0.9685 - val_loss: 0.1183\n",
            "Epoch 30/30\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.1129 - val_accuracy: 0.9672 - val_loss: 0.1177\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b98b6475c60>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size,\n",
        "          validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T73snva6L-Fq"
      },
      "source": [
        "### Predict Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY7hMzDBMAbD",
        "outputId": "bce99204-49b2-4427-9af0-ba05fee264b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "pred,shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(X_test)\n",
        "print(f'pred,shape: {pred.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxmrzlDEMVRF",
        "outputId": "f5b2ec6a-ed12-4be9-b5c9-67634f2d66ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5016589  0.1418801  0.7851711  0.8209257  0.0392064  0.47451612\n",
            " 0.00235043 0.9998859  0.15147945 0.8762447 ]\n",
            "cat_pred.shape: (10000,)\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "# getting categorical prediction\n",
        "# the output neuron with maximum value (among the 10 neurons)\n",
        "# corersponds to the prediction\n",
        "\n",
        "print(pred[0])\n",
        "cat_pred = np.argmax(pred, axis=1)\n",
        "print(f'cat_pred.shape: {cat_pred.shape}')\n",
        "print(cat_pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9FMhy2rAXDR",
        "outputId": "e3c9ee83-fda6-4622-afd8-3518c76acc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9585\n"
          ]
        }
      ],
      "source": [
        "# compute the test accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(accuracy_score(y_test, cat_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upuOF-3tCDjo"
      },
      "source": [
        "## Exercise:\n",
        "* ## Split the training data into train and validation sets (use for instance 80% and 20%)\n",
        "* ## Operate a model selection for the following hyper-parameters\n",
        "1. ### **number of layers**, for instance try (1 or 2 hidden layers)\n",
        "2. ### **Number of hidden units** fixed the numer of layers (256 or 1024)\n",
        "3. ### **Batch size** (try 32 or 128). What main  differences do you observe?\n",
        "4. ### **Number of epochs** if needed increase it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B18uJuLUCo9W"
      },
      "source": [
        "1. Split training data into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELBV88eCCl1X",
        "outputId": "6863ae79-1ac6-4d87-caa4-a5527a7f6627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape:(48000, 784),val_data.shape:(12000, 784)\n",
            "train_lab.shape:(48000,),val_lab.shape:(12000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, val_data, train_lab, val_lab = train_test_split(X_train, y_train,\n",
        "                                                            test_size=0.2)\n",
        "\n",
        "print(f\"train_data.shape:{train_data.shape},val_data.shape:{val_data.shape}\")\n",
        "print(f\"train_lab.shape:{train_lab.shape},val_lab.shape:{val_lab.shape}\")\n",
        "\n",
        "## use following code to merge againg train and validation data for the final training\n",
        "\n",
        "#X_train = np.concatenate([train_data, val_data])\n",
        "#y_train = np.concatenate([train_lab, test_lab])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nsvKZBKD8Gx"
      },
      "source": [
        "2. Fix a set of possible configurations of all hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "93kxKIPuGbwM"
      },
      "outputs": [],
      "source": [
        "n_layers = [1, 2]\n",
        "n_hidden_units = [256, 1024]\n",
        "batch_sizes = [32, 128]\n",
        "\n",
        "n_epochs = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVEAhikgSX9A"
      },
      "source": [
        "3. Loop over any possible configuration\n",
        "\n",
        "  - for any config, train a model on training data\n",
        "\n",
        "  - Evaluate the performance on validation data\n",
        "\n",
        "  - Pic the configuration having the highest accuracy on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "T_egK2leScRn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "# for reproducibility\n",
        "def setRandomSeed(seed):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "def defineModelAndTrain(n_layers, n_hidden_units, batch_size, seed=42):\n",
        "    setRandomSeed(seed)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_shape=(28*28,), activation='sigmoid'))\n",
        "    for _ in range(n_layers):\n",
        "        model.add(Dense(n_hidden_units, activation='sigmoid'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_data, train_lab, epochs=n_epochs,\n",
        "              batch_size=batch_size, verbose=0)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssWflXpIhY8x",
        "outputId": "b71b74d6-af7e-487c-fd1f-4b7e7ed1f061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (1, 256, 32) -> accuracy: 0.9581666666666667\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (1, 256, 128) -> accuracy: 0.9368333333333333\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (1, 1024, 32) -> accuracy: 0.9556666666666667\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Configuration: (1, 1024, 128) -> accuracy: 0.939\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (2, 256, 32) -> accuracy: 0.9493333333333334\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (2, 256, 128) -> accuracy: 0.9229166666666667\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (2, 1024, 32) -> accuracy: 0.9521666666666667\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (2, 1024, 128) -> accuracy: 0.9284166666666667\n",
            "Max accuracy: 0.9581666666666667 with configuration (1, 256, 32)\n"
          ]
        }
      ],
      "source": [
        "# Running the model selection\n",
        "# Selecting the configuration with the highest accuracy on the validation data\n",
        "\n",
        "max_accuracy = -1\n",
        "max_accuracy_model_config = None\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "for layers in n_layers:\n",
        "    for hidden_units in n_hidden_units:\n",
        "        for batch_size in batch_sizes:\n",
        "            model = defineModelAndTrain(layers, hidden_units, batch_size)\n",
        "\n",
        "            pred = model.predict(val_data)\n",
        "            acc = accuracy_score(val_lab, np.argmax(pred, axis=1))\n",
        "\n",
        "            print(f'Configuration: {(layers, hidden_units, batch_size)} -> accuracy: {acc}')\n",
        "\n",
        "            if acc > max_accuracy:\n",
        "                max_accuracy, max_accuracy_model_config = acc, (layers, hidden_units, batch_size)\n",
        "\n",
        "print(f'Max accuracy: {max_accuracy} with configuration {max_accuracy_model_config}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6Di47aIh1vf",
        "outputId": "fe804e65-896f-4684-8477-4cfa685f1aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (n_layers, n_hidden_units, batch_size): (1, 256, 32) -> acc: 0.95675\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (n_layers, n_hidden_units, batch_size): (1, 256, 128) -> acc: 0.93725\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (n_layers, n_hidden_units, batch_size): (1, 1024, 32) -> acc: 0.9573333333333334\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (n_layers, n_hidden_units, batch_size): (1, 1024, 128) -> acc: 0.9390833333333334\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (n_layers, n_hidden_units, batch_size): (2, 256, 32) -> acc: 0.95075\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (n_layers, n_hidden_units, batch_size): (2, 256, 128) -> acc: 0.9275\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (n_layers, n_hidden_units, batch_size): (2, 1024, 32) -> acc: 0.95\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Configuration: (n_layers, n_hidden_units, batch_size): (2, 1024, 128) -> acc: 0.928\n",
            "Max accuracy: 0.9573333333333334 with configuration (1, 1024, 32)\n"
          ]
        }
      ],
      "source": [
        "# Alternatively, equivalent solution using itertools library\n",
        "from sklearn.metrics import accuracy_score\n",
        "import itertools\n",
        "\n",
        "max_accuracy = -1\n",
        "max_accuracy_model_config = None\n",
        "\n",
        "# Cartesian product of the 'sets' of candidate values of parameters\n",
        "candidate_configurations = itertools.product(n_layers, n_hidden_units, batch_sizes)\n",
        "# print(list(candidate_configurations))\n",
        "\n",
        "for config in candidate_configurations:\n",
        "\n",
        "    model = defineModelAndTrain(*config)\n",
        "\n",
        "    pred = model.predict(val_data)\n",
        "    acc = accuracy_score(val_lab, np.argmax(pred, axis=1))\n",
        "\n",
        "    print(f\"Configuration: (n_layers, n_hidden_units, batch_size): {config} -> acc: {acc}\")\n",
        "\n",
        "    if acc > max_accuracy:\n",
        "        max_accuracy, max_accuracy_model_config = acc, config\n",
        "\n",
        "print(f\"Max accuracy: {max_accuracy} with configuration {max_accuracy_model_config}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAJFHtKjnXtG"
      },
      "source": [
        "4. Merge again train and validation data to get a unique training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SRPgar8olXkC"
      },
      "outputs": [],
      "source": [
        "# Merging training and validation data\n",
        "\n",
        "X_train = np.concatenate([train_data, val_data])\n",
        "y_train = np.concatenate([train_lab, val_lab])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArBG_SQ3nihV"
      },
      "source": [
        "5. Train the final model with the chosen configuration and evaluate it on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxmJ9Aq5ngwc",
        "outputId": "fa95ae0a-748c-4bff-f83d-b104b9410ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Accuracy: 0.9605\n"
          ]
        }
      ],
      "source": [
        "# training a final model with the best configuration\n",
        "# predicting the test data to compute the final estimate of model accuracy\n",
        "\n",
        "n_layers, n_hidden_units, batch_size = max_accuracy_model_config\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(28*28,), activation='sigmoid'))\n",
        "for _ in range(n_layers):\n",
        "    model.add(Dense(n_hidden_units, activation='sigmoid'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, np.argmax(pred, axis=1))\n",
        "\n",
        "print(f'Accuracy: {acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYdOK7X9q5R9"
      },
      "source": [
        "### Exploring the fit() cunction\n",
        "\n",
        "- We know redefine the fit content line by line\n",
        "- We define a custom model, subclass of t.keras.Model\n",
        "- Need to redefine the train_step() method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "omHKIGQYrIRl"
      },
      "outputs": [],
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def train_step(self, data):\n",
        "        # unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to fit()\n",
        "        x, y = data\n",
        "        # GradientTape is necessary for automatic differentiation\n",
        "        # it is used to record ('tape') a sequence of operations\n",
        "        # performed upon some input and producing some output, so that the output can\n",
        "        # be differentiated with respect to the input\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True) # forward pass\n",
        "            # compute the loss value\n",
        "            # the loss function is configured in compile()\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "            # select parameter\n",
        "            trainable_vars = self.trainable_variables\n",
        "            # compute gradients w.r.t. parameters\n",
        "            gradients = tape.gradient(loss, trainable_vars)\n",
        "            # update weights\n",
        "            self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "            # update metrics and store them in the object (includes the metric that tracks the loss)\n",
        "            self.compiled_metrics.update_state(y, y_pred)\n",
        "            # return a dict mapping metric names to current value\n",
        "            return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoHhA_AOJ8_c"
      },
      "source": [
        "- Now we redefine the model with class CustomModel\n",
        "  - We cannot use Sequential, we need to say which are the input and output layers\n",
        "  - We will use the Input layer of Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rMa2h5cKKqy",
        "outputId": "b30e520a-7979-4f48-a516-ff5270e0dda6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6054 - loss: 0.4986 - val_accuracy: 0.8716 - val_loss: 0.6396\n",
            "Epoch 2/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.4964 - val_accuracy: 0.8997 - val_loss: 0.4064\n",
            "Epoch 3/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.4897 - val_accuracy: 0.9148 - val_loss: 0.3329\n",
            "Epoch 4/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.4860 - val_accuracy: 0.9211 - val_loss: 0.2991\n",
            "Epoch 5/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.4844 - val_accuracy: 0.9261 - val_loss: 0.2756\n",
            "Epoch 6/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.4840 - val_accuracy: 0.9301 - val_loss: 0.2548\n",
            "Epoch 7/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.4821 - val_accuracy: 0.9363 - val_loss: 0.2382\n",
            "Epoch 8/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.4813 - val_accuracy: 0.9371 - val_loss: 0.2286\n",
            "Epoch 9/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.4796 - val_accuracy: 0.9402 - val_loss: 0.2161\n",
            "Epoch 10/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.4757 - val_accuracy: 0.9427 - val_loss: 0.2073\n",
            "Epoch 11/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.4769 - val_accuracy: 0.9448 - val_loss: 0.2026\n",
            "Epoch 12/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.4755 - val_accuracy: 0.9442 - val_loss: 0.1972\n",
            "Epoch 13/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.4755 - val_accuracy: 0.9433 - val_loss: 0.1968\n",
            "Epoch 14/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.4757 - val_accuracy: 0.9507 - val_loss: 0.1831\n",
            "Epoch 15/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.4756 - val_accuracy: 0.9496 - val_loss: 0.1801\n",
            "Epoch 16/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.4745 - val_accuracy: 0.9495 - val_loss: 0.1813\n",
            "Epoch 17/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9568 - loss: 0.4746 - val_accuracy: 0.9509 - val_loss: 0.1733\n",
            "Epoch 18/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.4731 - val_accuracy: 0.9512 - val_loss: 0.1730\n",
            "Epoch 19/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.4718 - val_accuracy: 0.9534 - val_loss: 0.1638\n",
            "Epoch 20/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.4708 - val_accuracy: 0.9538 - val_loss: 0.1652\n",
            "Epoch 21/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9624 - loss: 0.4733 - val_accuracy: 0.9538 - val_loss: 0.1673\n",
            "Epoch 22/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.4728 - val_accuracy: 0.9538 - val_loss: 0.1635\n",
            "Epoch 23/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9633 - loss: 0.4726 - val_accuracy: 0.9557 - val_loss: 0.1526\n",
            "Epoch 24/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9644 - loss: 0.4703 - val_accuracy: 0.9564 - val_loss: 0.1525\n",
            "Epoch 25/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.4740 - val_accuracy: 0.9555 - val_loss: 0.1525\n",
            "Epoch 26/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.4715 - val_accuracy: 0.9578 - val_loss: 0.1528\n",
            "Epoch 27/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9652 - loss: 0.4701 - val_accuracy: 0.9573 - val_loss: 0.1524\n",
            "Epoch 28/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.4701 - val_accuracy: 0.9574 - val_loss: 0.1484\n",
            "Epoch 29/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.4689 - val_accuracy: 0.9589 - val_loss: 0.1472\n",
            "Epoch 30/30\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.4683 - val_accuracy: 0.9571 - val_loss: 0.1468\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b98bedc2c20>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#model = Sequential()\n",
        "#model.add(Dense(256, input_shape=(28*28,), activation='sigmoid'))\n",
        "#model.add(Dense(128, activation='sigmoid'))\n",
        "#model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "input = tf.keras.Input(shape=(28*28,))\n",
        "hid = tf.keras.layers.Dense(256, activation='sigmoid')(input)\n",
        "hid = tf.keras.layers.Dense(128, activation='sigmoid')(hid)\n",
        "output = tf.keras.layers.Dense(num_classes, activation='sigmoid')(hid)\n",
        "\n",
        "model = CustomModel(input, output)\n",
        "\n",
        "model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "batsh_size = 64\n",
        "epochs = 30\n",
        "model.fit(X_train, y_train, epochs=epochs, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHMM6lJ_LG-H",
        "outputId": "04485428-eea5-42d6-8af9-be549beec86f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "0.9572\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(X_test)\n",
        "cat_pred = np.argmax(pred, axis=1)\n",
        "print(accuracy_score(y_test, cat_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPwsHtOH2sZ5C6GsInU1xr8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}